{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d615a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Python 3.10.0: https://www.python.org/ftp/python/3.10.0/python-3.10.0-amd64.exe\n",
    "# (optionally) upgrade pip: python3 -m pip install --upgrade pip\n",
    "\n",
    "# pip install wheel\n",
    "# pip install unstructured[local-inference]\n",
    "# pip install poppler-utils\n",
    "# pip install git+https://github.com/facebookresearch/detectron2.git\n",
    "\n",
    "# Download tesseract-ocr: https://digi.bib.uni-mannheim.de/tesseract/tesseract-ocr-w64-setup-5.3.1.20230401.exe\n",
    "# Download poppler: https://github.com/oschwartz10612/poppler-windows/releases/download/v23.01.0-0/Release-23.01.0-0.zip\n",
    "# Put poppler in path: C:\\Program Files\\Poppler\\Library\\bin\n",
    "\n",
    "# pip install langchain\n",
    "# pip install pinecone-client[grpc]\n",
    "# pip install tiktoken\n",
    "# pip install python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d3e92ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract as pt\n",
    "\n",
    "pt.pytesseract.tesseract_cmd = \"C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe\"\n",
    "\n",
    "from langchain.document_loaders import UnstructuredPDFLoader, OnlinePDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5166d759",
   "metadata": {},
   "source": [
    "### Load your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4a2d6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredPDFLoader(\"../data/field-guide-to-data-science.pdf\")\n",
    "# loader = OnlinePDFLoader(\"https://wolfpaulus.com/wp-content/uploads/2017/05/field-guide-to-data-science.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcdac23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bcd333f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"../data/field-guide-to-data-science.pkl\", \"wb\") as f:\n",
    "    pickle.dump(data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4fd7c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 1 document(s) in your data\n",
      "There are 167575 characters in your document\n"
     ]
    }
   ],
   "source": [
    "print (f'You have {len(data)} document(s) in your data')\n",
    "print (f'There are {len(data[0].page_content)} characters in your document')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af9b604",
   "metadata": {},
   "source": [
    "### Chunk your data up into smaller documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb3c6f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "879873a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now you have 226 documents\n"
     ]
    }
   ],
   "source": [
    "print (f'Now you have {len(texts)} documents')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838b2843",
   "metadata": {},
   "source": [
    "### Create embeddings of your documents to get ready for semantic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "373e695a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma, Pinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e093ef3",
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_API_ENV = os.getenv(\"PINECONE_API_ENV\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e0d1c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0deb2f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize pinecone\n",
    "pinecone.init(\n",
    "    api_key=PINECONE_API_KEY,  # find at app.pinecone.io\n",
    "    environment=PINECONE_API_ENV  # next to api key in console\n",
    ")\n",
    "index_name = \"test\" # put in the name of your pinecone index here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "388988ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = Pinecone.from_texts([t.page_content for t in texts], embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34929595",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are examples of good data science teams?\"\n",
    "docs = docsearch.similarity_search(query, include_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e0f5b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'At Booz Allen Hamilton, we built an industry-leading team of Data Scientists. Over the course of hundreds of analytic challenges for countless clients, weâ€™ve unraveled the DNA of Data Science. Many people have put forth their thoughts on single aspec'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's an example of the first document that was returned\n",
    "docs[0].page_content[:250]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c35dcd9",
   "metadata": {},
   "source": [
    "### Query those docs to get your answer back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f051337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b9b1c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f67ea7c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Data Science is the art of turning data into actions. This is accomplished through the creation of data products, which provide actionable information without exposing decision makers to the underlying data or analytics (e.g., buy/sell strategies for financial instruments, a set of actions to improve product yield, or steps to optimize processes).'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is data science?\"\n",
    "docs = docsearch.similarity_search(query, include_metadata=True)\n",
    "chain.run(input_documents=docs, question=query)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "c5d01433c49bebc7c0f039aefb7a5f7006b5cc5372ab57f4229212c8564f15fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

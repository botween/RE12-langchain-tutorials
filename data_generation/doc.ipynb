{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import chromadb\n",
    "import pickle\n",
    "import pytesseract as pt\n",
    "from dotenv import load_dotenv\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.document_loaders import UnstructuredPDFLoader, OnlinePDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "llm = OpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "pt.pytesseract.tesseract_cmd = \"C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatDoc:\n",
    "    def __init__(self, fileName: str):\n",
    "        self.fileName = fileName\n",
    "        self.init()\n",
    "\n",
    "    def load_from_pdf(self):\n",
    "        loader = UnstructuredPDFLoader(f\"../data/{self.fileName}.pdf\")\n",
    "        self.data = loader.load()\n",
    "        self.save_to_pkl()\n",
    "\n",
    "    def load_from_pkl(self):\n",
    "        with open(f\"../data/{self.fileName}.pkl\", \"rb\") as f:\n",
    "            self.data = pickle.load(f)\n",
    "\n",
    "    def save_to_pkl(self):\n",
    "        with open(f\"../data/{self.fileName}.pkl\", \"wb\") as f:\n",
    "            pickle.dump(self.data, f)\n",
    "\n",
    "    def init(self):\n",
    "        if os.path.exists(f\"../data/chroma/{self.fileName}\"):\n",
    "            self.docsearch = Chroma(persist_directory=f\"../data/chroma/{self.fileName}\", embedding_function=embeddings, collection_name=self.fileName)\n",
    "            return\n",
    "        \n",
    "        if os.path.exists(f\"../data/{self.fileName}.pkl\"):\n",
    "            self.load_from_pkl()\n",
    "        else:\n",
    "            self.load_from_pdf()\n",
    "\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000, chunk_overlap=0\n",
    "        )\n",
    "        self.texts = self.text_splitter.split_documents(self.data)\n",
    "\n",
    "        self.docsearch = Chroma.from_texts(\n",
    "            [t.page_content for t in self.texts],\n",
    "            embeddings,\n",
    "            collection_name=self.fileName,\n",
    "            persist_directory=f\"../data/chroma/{self.fileName}\",\n",
    "        )\n",
    "\n",
    "        self.docsearch.persist()\n",
    "\n",
    "    def query(self, q: str):\n",
    "        docs = self.docsearch.similarity_search(q, include_metadata=True)\n",
    "        chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "        return str(chain.run(input_documents=docs, question=q)).strip()\n",
    "\n",
    "    def summarize(self):\n",
    "        chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
    "        return str(chain.run(self.texts[:5])).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB with persistence: data will be stored in: ../data/chroma/deepfake\n"
     ]
    }
   ],
   "source": [
    "deepfake = ChatDoc(\"deepfake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This document discusses potential solutions to the problem of deepfakes, which are AI-generated images and videos that can be used to spread false information. One solution is C2PA, which cryptographically signs any content created by a device and documents who captured the image, where, and when. Other options include fingerprinting and watermarking images and videos. AI tools have been proposed to spot deepfakes, but this technology is not reliable enough to keep up with the constantly changing generative AI tools. Another potential solution is to develop an instant fact-checker for social media users, which would quickly inform users of the veracity of a piece of content.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepfake.query(\"Summarize the document?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ef4b2fc86474f308c2c162d8320f47a1bbfdce1148fdd81da886bfd477849216"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
